# astrbot_plugin_GroupFS/main.py

# è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–: pip install croniter aiohttp chardet apscheduler
import asyncio
import os
from typing import List, Dict, Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler

import croniter

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger
import astrbot.api.message_components as Comp
from aiocqhttp.exceptions import ActionFailed 

from .src import utils
from .src.file_ops import (
    get_all_files_with_path, 
    download_and_save_file, 
    create_zip_archive, 
    cleanup_folder, 
    cleanup_backup_temp,
    get_all_files_recursive_core
)
from .src.preview_utils import get_file_preview
from .src.utils import send_or_forward
from .src.actions import (
    perform_scheduled_check, 
    perform_batch_check_and_delete,
    perform_batch_delete,
    check_storage_and_notify
)
from .src.backup import perform_group_file_backup
from .src.duplicate_check import detect_duplicates
from .src.session_manager import SessionManager


@register(
    "astrbot_plugin_GroupFS",
    "Foolllll",
    "ç®¡ç†QQç¾¤æ–‡ä»¶",
    "0.9",
    "https://github.com/Foolllll-J/astrbot_plugin_GroupFS"
)
class GroupFSPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict] = None):
        super().__init__(context)
        self.config = config if config else {}
        self.group_whitelist: List[int] = [int(g) for g in self.config.get("group_whitelist", [])]
        self.admin_users: List[int] = [int(u) for u in self.config.get("admin_users", [])]
        self.preview_length: int = self.config.get("preview_length", 300)
        self.storage_limits: Dict[int, Dict] = {}
        self.cron_configs = []
        self.bot = None
        self.forward_threshold: int = self.config.get("forward_threshold", 0)
        self.scheduler: Optional[AsyncIOScheduler] = None
        
        self.active_tasks = [] 
        
        self.default_zip_password: str = self.config.get("default_zip_password", "")
        self.download_semaphore = asyncio.Semaphore(5)
        
        self.scheduled_autodelete: bool = self.config.get("scheduled_autodelete", False)

        limit_configs = self.config.get("storage_limits", [])
        for item in limit_configs:
            try:
                group_id_str, count_limit_str, space_limit_str = item.split(':')
                group_id = int(group_id_str)
                self.storage_limits[group_id] = { "count_limit": int(count_limit_str), "space_limit_gb": float(space_limit_str) }
            except ValueError as e:
                logger.error(f"è§£æ storage_limits é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        self.backup_zip_password: str = self.config.get("backup_zip_password", "")
        self.backup_file_size_limit_mb: int = self.config.get("backup_file_size_limit_mb", 0)
        ext_str: str = self.config.get("backup_file_extensions", "txt,zip")
        
        self.backup_file_extensions: List[str] = [
            ext.strip().lstrip('.').lower()
            for ext in ext_str.split(',') 
            if ext.strip()
        ]

        # æœç´¢ä¼šè¯ç®¡ç†
        self.search_cache_timeout = 600 # 10åˆ†é’Ÿ
        self.search_results_per_page = 20
        self.session_mgr = SessionManager(timeout=self.search_cache_timeout)

        cron_configs = self.config.get("scheduled_check_tasks", [])
        seen_tasks = set()
        for item in cron_configs:
            try:
                group_id_str, cron_str = item.split(':', 1)
                group_id = int(group_id_str)
                if not croniter.croniter.is_valid(cron_str):
                    raise ValueError(f"æ— æ•ˆçš„ cron è¡¨è¾¾å¼: {cron_str}")
                
                task_identifier = (group_id, cron_str)
                if task_identifier in seen_tasks:
                    logger.warning(f"æ£€æµ‹åˆ°é‡å¤çš„å®šæ—¶ä»»åŠ¡é…ç½® '{item}'ï¼Œå·²è·³è¿‡ã€‚")
                    continue
                
                self.cron_configs.append({"group_id": group_id, "cron_str": cron_str})
                seen_tasks.add(task_identifier)
            except ValueError as e:
                logger.error(f"è§£æ scheduled_check_tasks é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²åŠ è½½ã€‚")

    async def initialize(self):
        if self.cron_configs:
            logger.info("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥è°ƒåº¦å™¨...")
            self.scheduler = AsyncIOScheduler()
            self._register_jobs()
            self.scheduler.start()

    def _register_jobs(self):
        """æ ¹æ®é…ç½®æ³¨å†Œå®šæ—¶ä»»åŠ¡"""
        for job_config in self.cron_configs:
            group_id = job_config["group_id"]
            cron_str = job_config["cron_str"]
            job_id = f"scheduled_check_{group_id}_{cron_str.replace(' ', '_')}"
            
            if self.scheduler.get_job(job_id):
                logger.warning(f"ä»»åŠ¡ {job_id} å·²å­˜åœ¨ï¼Œè·³è¿‡æ³¨å†Œã€‚")
                continue
            
            try:
                cron_parts = cron_str.split()
                minute, hour, day, month, day_of_week = cron_parts
                
                self.scheduler.add_job(
                    self._perform_scheduled_check,
                    "cron",
                    args=[group_id, self.scheduled_autodelete],
                    minute=minute,
                    hour=hour,
                    day=day,
                    month=month,
                    day_of_week=day_of_week,
                    id=job_id
                )
                logger.info(f"æˆåŠŸæ³¨å†Œå®šæ—¶ä»»åŠ¡: group_id={group_id}, cron_str='{cron_str}'")
            except Exception as e:
                logger.error(f"æ³¨å†Œå®šæ—¶ä»»åŠ¡ '{cron_str}' å¤±è´¥: {e}", exc_info=True)

    async def _send_or_forward(self, event: AstrMessageEvent, text: str, name: str = "GroupFS"):
        await send_or_forward(event, text, self.forward_threshold, name)

    async def _perform_scheduled_check(self, group_id: int, auto_delete: bool):
        await perform_scheduled_check(group_id, auto_delete, self.bot, self.storage_limits, self.scheduled_autodelete)


    async def _get_all_files_with_path(self, group_id: int, bot) -> List[Dict]:
        return await get_all_files_with_path(group_id, bot)
    
    async def _get_all_files_recursive_core(self, group_id: int, bot) -> List[Dict]:
        """
        å…¼å®¹ /cdf, /cf, /sf, /df ç­‰æŒ‡ä»¤ã€‚
        """
        return await get_all_files_recursive_core(group_id, bot)
    
    async def _download_and_save_file(self, group_id: int, file_id: str, file_name: str, file_size: int, relative_path: str, root_dir: str, client) -> bool:
        return await download_and_save_file(group_id, file_id, file_name, file_size, relative_path, root_dir, client, self.download_semaphore)

    async def _cleanup_backup_temp(self, backup_dir: str, zip_path: Optional[str]):
        await cleanup_backup_temp(backup_dir, zip_path)

    @filter.command("cdf")
    async def on_check_and_delete_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cdf å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŒ‡ä»¤ã€‚")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        await event.send(MessageChain([Comp.Plain("âš ï¸ è­¦å‘Šï¼šå³å°†å¼€å§‹æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶ï¼\næ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå®Œæˆåå°†å‘é€æŠ¥å‘Šã€‚")]))
        self.active_tasks.append(asyncio.create_task(self._perform_batch_check_and_delete(event)))
        event.stop_event()

    async def _perform_batch_check_and_delete(self, event: AstrMessageEvent):
        await perform_batch_check_and_delete(event, self.forward_threshold)

    @filter.command("cf")
    async def on_check_files_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cf å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŒ‡ä»¤ã€‚")
        await event.send(MessageChain([Comp.Plain("âœ… å·²å¼€å§‹æ‰«æç¾¤å†…æ‰€æœ‰æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±æ•ˆæ–‡ä»¶...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚\nå¦‚æœæœªå‘ç°å¤±æ•ˆæ–‡ä»¶ï¼Œå°†ä¸ä¼šå‘é€ä»»ä½•æ¶ˆæ¯ã€‚")]))
        self.active_tasks.append(asyncio.create_task(self._perform_scheduled_check(group_id, False)))
        event.stop_event()
    
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE, priority=10)
    async def on_group_file_upload(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        has_file = any(isinstance(seg, Comp.File) for seg in event.get_messages())
        if has_file:
            group_id = int(event.get_group_id())
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°æ–‡ä»¶ä¸Šä¼ äº‹ä»¶ï¼Œå°†åœ¨5ç§’åè§¦å‘å®¹é‡æ£€æŸ¥ã€‚")
            self.active_tasks.append(asyncio.create_task(self._check_storage_and_notify(event)))

    async def _check_storage_and_notify(self, event: AstrMessageEvent):
        await check_storage_and_notify(event, self.storage_limits)
    
    def _format_search_results(self, files: List[Dict], search_term: str, for_delete: bool = False) -> str:
        return utils.format_search_results(files, search_term, for_delete)
    
    @filter.command("sf")
    async def on_search_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦æœç´¢çš„æ–‡ä»¶åã€‚ç”¨æ³•: /sf <æ–‡ä»¶å> [åºå·]")]))
            return
            
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¿»é¡µæŒ‡ä»¤ (ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ–‡ä»¶åæ˜¯ 'n' ä¸”å­˜åœ¨ä¼šè¯)
        if filename_to_find.lower() == 'n':
            session = self.session_mgr.get_session(group_id, user_id)
            if session:
                await self._show_search_page(event, session, session.current_page + 1)
                return

        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /sf, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰ä¼šè¯ä¸”å…³é”®è¯åŒ¹é…
        session = self.session_mgr.get_session(group_id, user_id)
        if session and session.keyword == filename_to_find and index_str:
            # å¦‚æœæœ‰åºå·ä¸”å…³é”®è¯åŒ¹é…ï¼Œç›´æ¥ä»ä¼šè¯ä¸­å–æ–‡ä»¶é¢„è§ˆ
            try:
                index = int(index_str)
                if 1 <= index <= session.total_count:
                    file_to_preview = session.results[index - 1]
                    await self._handle_preview(event, file_to_preview)
                    return
            except ValueError:
                pass

        # é‡æ–°æœç´¢
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ã€‚")

        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªåœ¨ç¾¤æ–‡ä»¶ä¸­æ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
            
        # åˆ›å»ºæ–°ä¼šè¯
        session = self.session_mgr.create_session(group_id, user_id, filename_to_find, found_files, self.search_results_per_page)
        
        if index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_preview = found_files[index - 1]
                    await self._handle_preview(event, file_to_preview)
                    return
                else:
                    await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                    return
            except ValueError:
                await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
                return
        
        # æ˜¾ç¤ºç¬¬ä¸€é¡µ
        await self._show_search_page(event, session, 1)

    async def _show_search_page(self, event: AstrMessageEvent, session, page: int):
        total_pages = (session.total_count + session.page_size - 1) // session.page_size
        if page > total_pages:
            await event.send(MessageChain([Comp.Plain("âš ï¸ å·²ç»æ˜¯æœ€åä¸€é¡µäº†ã€‚")]))
            return
        
        session.current_page = page
        results = session.get_page_results(page)
        
        reply_text = f"ğŸ” æ‰¾åˆ°äº† {session.total_count} ä¸ªä¸ã€Œ{session.keyword}ã€ç›¸å…³çš„ç»“æœ (ç¬¬ {page}/{total_pages} é¡µ)ï¼š\n"
        reply_text += "-" * 20
        
        start_idx = (page - 1) * session.page_size + 1
        for i, file_info in enumerate(results, start_idx):
            reply_text += (
                f"\n[{i}] {file_info.get('file_name')}"
                f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
                f"\n  å¤§å°: {utils.format_bytes(file_info.get('size'))}"
                f"\n  ä¿®æ”¹æ—¶é—´: {utils.format_timestamp(file_info.get('modify_time'))}"
            )
        
        reply_text += "\n" + "-" * 20
        if page < total_pages:
            reply_text += f"\nè¾“å…¥ /sf n æŸ¥çœ‹ä¸‹ä¸€é¡µ"
        reply_text += f"\nå¦‚éœ€é¢„è§ˆ/åˆ é™¤ï¼Œè¯·ä½¿ç”¨ /sf {session.keyword} [åºå·] æˆ– /df {session.keyword} [åºå·]"
        
        await self._send_or_forward(event, reply_text, name="æ–‡ä»¶æœç´¢ç»“æœ")

    async def _handle_preview(self, event: AstrMessageEvent, file_to_preview: dict):
        group_id = int(event.get_group_id())
        try:
            preview_text, error_msg = await self._get_file_preview(event, file_to_preview)
            if error_msg:
                await event.send(MessageChain([Comp.Plain(error_msg)]))
                return
            
            reply_text = (
                f"ğŸ“„ æ–‡ä»¶ã€Œ{file_to_preview.get('file_name')}ã€å†…å®¹é¢„è§ˆï¼š\n"
                + "-" * 20 + "\n"
                + preview_text
            )
            await self._send_or_forward(event, reply_text, name=f"æ–‡ä»¶é¢„è§ˆï¼š{file_to_preview.get('file_name')}")
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain("âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    @filter.command("df")
    async def on_delete_file_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        group_id = int(event.get_group_id())
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split(maxsplit=2)
        if len(command_parts) < 2 or not command_parts[1]:
            await event.send(MessageChain([Comp.Plain("â“ è¯·æä¾›è¦åˆ é™¤çš„æ–‡ä»¶åã€‚ç”¨æ³•: /df <æ–‡ä»¶å> [åºå·]")]))
            return
        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘åˆ é™¤æŒ‡ä»¤ /df, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")]))
            return

        # å°è¯•ä»ä¼šè¯ä¸­è·å–
        session = self.session_mgr.get_session(group_id, user_id)
        found_files = []
        if session and session.keyword == filename_to_find:
            found_files = session.results
        else:
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            for file_info in all_files:
                current_filename = file_info.get('file_name', '')
                base_name, _ = os.path.splitext(current_filename)
                if filename_to_find in base_name or filename_to_find in current_filename:
                    found_files.append(file_info)

        logger.info(f"[{group_id}] åœ¨æœç´¢ä¸­æ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ç”¨äºåˆ é™¤ã€‚")
            
        if not found_files:
            await event.send(MessageChain([Comp.Plain(f"âŒ æœªæ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")]))
            return
            
        if index_str == '0':
            self.active_tasks.append(asyncio.create_task(self._perform_batch_delete(event, found_files)))
            event.stop_event()
            return

        file_to_delete = None
        if len(found_files) == 1 and not index_str:
            file_to_delete = found_files[0]
        elif index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_delete = found_files[index - 1]
                else:
                    await event.send(MessageChain([Comp.Plain(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")]))
                    return
            except ValueError:
                await event.send(MessageChain([Comp.Plain("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")]))
                return
        else:
            # å¦‚æœæ²¡æä¾›åºå·ä¸”æœ‰å¤šä¸ªç»“æœï¼Œåˆ›å»º/æ›´æ–°ä¼šè¯å¹¶æ˜¾ç¤ºç»“æœ
            session = self.session_mgr.create_session(group_id, user_id, filename_to_find, found_files, self.search_results_per_page)
            await self._show_search_page(event, session, 1)
            return

        if not file_to_delete:
            await event.send(MessageChain([Comp.Plain("âŒ å†…éƒ¨é”™è¯¯ï¼Œæœªèƒ½ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶ã€‚")]))
            return
        
        try:
            file_id_to_delete = file_to_delete.get("file_id")
            found_filename = file_to_delete.get("file_name")
            if not file_id_to_delete:
                await event.send(MessageChain([Comp.Plain(f"âŒ æ‰¾åˆ°æ–‡ä»¶ã€Œ{found_filename}ã€ï¼Œä½†æ— æ³•è·å–å…¶IDï¼Œåˆ é™¤å¤±è´¥ã€‚")]))
                return
            logger.info(f"[{group_id}] ç¡®è®¤åˆ é™¤æ–‡ä»¶ '{found_filename}', File ID: {file_id_to_delete}...")
            client = event.bot
            delete_result = await client.api.call_action('delete_group_file', group_id=group_id, file_id=file_id_to_delete)
            is_success = False
            if delete_result:
                trans_result = delete_result.get('transGroupFileResult', {})
                result_obj = trans_result.get('result', {})
                if result_obj.get('retCode') == 0:
                    is_success = True
            if is_success:
                await event.send(MessageChain([Comp.Plain(f"âœ… æ–‡ä»¶ã€Œ{found_filename}ã€å·²æˆåŠŸåˆ é™¤ã€‚")]))
                logger.info(f"[{group_id}] æ–‡ä»¶ '{found_filename}' å·²æˆåŠŸåˆ é™¤ã€‚")
                # åˆ é™¤æˆåŠŸåï¼Œå¦‚æœä¼šè¯å­˜åœ¨ï¼Œä»ä¼šè¯ä¸­ç§»é™¤
                if session and session.keyword == filename_to_find:
                    session.results.remove(file_to_delete)
                    session.total_count = len(session.results)
                    if session.total_count == 0:
                        self.session_mgr.clear_session(group_id, user_id)
            else:
                error_msg = delete_result.get('wording', 'APIæœªè¿”å›æˆåŠŸçŠ¶æ€')
                await event.send(MessageChain([Comp.Plain(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{found_filename}ã€å¤±è´¥: {error_msg}")]))
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†åˆ é™¤æµç¨‹æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            await event.send(MessageChain([Comp.Plain(f"âŒ å¤„ç†åˆ é™¤æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")]))

    async def _perform_batch_delete(self, event: AstrMessageEvent, files_to_delete: List[Dict]):
        await perform_batch_delete(event, files_to_delete, self.forward_threshold)

    async def _cleanup_folder(self, path: str):
        await cleanup_folder(path)

    async def _get_file_preview(self, event: AstrMessageEvent, file_info: dict) -> tuple[str, str | None]:
        return await get_file_preview(
            int(event.get_group_id()), 
            file_info, 
            event.bot, 
            self.default_zip_password, 
            self.preview_length, 
            self.download_semaphore,
            self._cleanup_folder
        )

    async def _create_zip_archive(self, source_dir: str, target_zip_path: str, password: str) -> bool:
        return await create_zip_archive(source_dir, target_zip_path, password)

    async def _perform_group_file_backup(self, event: AstrMessageEvent, group_id: int, date_filter_timestamp: Optional[int] = None):
        await perform_group_file_backup(
            event, 
            group_id, 
            self.bot, 
            self.download_semaphore, 
            self.backup_file_size_limit_mb,
            self.backup_file_extensions,
            self.backup_zip_password,
            date_filter_timestamp
        )

    @filter.command("ddf")
    async def on_detect_duplicates_command(self, event: AstrMessageEvent):
        """æ£€æµ‹ç¾¤æ–‡ä»¶ä¸­çš„é‡å¤æ–‡ä»¶ï¼ˆä½¿ç”¨LLMåˆ†æï¼‰"""
        
        async for result in detect_duplicates(
            event, 
            self.bot, 
            self.context, 
            self.admin_users, 
            self.group_whitelist, 
            self._get_all_files_recursive_core, 
            self.text_to_image, 
            self._send_or_forward
        ):
            yield result

    @filter.command("gfb")
    async def on_group_file_backup_command(self, event: AstrMessageEvent):
        if not self.bot: self.bot = event.bot
        
        # 1. è§£æç›®æ ‡ç¾¤IDå’Œæ—¥æœŸå‚æ•°
        group_id_str = event.get_group_id()
        user_id = int(event.get_sender_id())
        
        command_parts = event.message_str.split()
        target_group_id: Optional[int] = None
        date_filter_timestamp: Optional[int] = None
        
        # è§£æå‚æ•°: /gfb [ç¾¤å·] [æ—¥æœŸ]
        if len(command_parts) > 1:
            try:
                target_group_id = int(command_parts[1])
                # å¦‚æœæœ‰ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œå°è¯•è§£æä¸ºæ—¥æœŸ
                if len(command_parts) > 2:
                    date_filter_timestamp = utils.parse_date_param(command_parts[2])
                    if date_filter_timestamp is None:
                        await event.send(MessageChain([Comp.Plain("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ã€‚æ”¯æŒæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD\nç¤ºä¾‹: /gfb 123456 2024-01-01")]))
                        return
            except ValueError:
                # å¯èƒ½ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ—¥æœŸè€Œä¸æ˜¯ç¾¤å·
                if group_id_str:
                    target_group_id = int(group_id_str)
                    date_filter_timestamp = utils.parse_date_param(command_parts[1])
                    if date_filter_timestamp is None:
                        await event.send(MessageChain([Comp.Plain("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·æä¾›æœ‰æ•ˆçš„ç¾¤å·æˆ–æ—¥æœŸã€‚\nç”¨æ³•: /gfb [ç¾¤å·] [æ—¥æœŸ]\næ—¥æœŸæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD")]))
                        return
                else:
                    await event.send(MessageChain([Comp.Plain("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·æä¾›æœ‰æ•ˆçš„ç¾¤å·ã€‚ç”¨æ³•: /gfb <ç¾¤å·> [æ—¥æœŸ]")]))
                    return
        elif group_id_str:
            # ç¾¤èŠä¸­ä¸”æ²¡æœ‰å‚æ•°ï¼Œå¤‡ä»½å½“å‰ç¾¤
            target_group_id = int(group_id_str)
        else:
            # ç§èŠä¸­ä¸”æ²¡æœ‰å‚æ•°
            await event.send(MessageChain([Comp.Plain("âŒ æ ¼å¼é”™è¯¯ï¼šåœ¨ç§èŠä¸­è¯·æŒ‡å®šè¦å¤‡ä»½çš„ç¾¤å·ã€‚\nç”¨æ³•: /gfb <ç¾¤å·> [æ—¥æœŸ]\næ—¥æœŸæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD")]))
            return

        logger.info(f"ç”¨æˆ· {user_id} è§¦å‘ /gfb å¤‡ä»½æŒ‡ä»¤ï¼Œç›®æ ‡ç¾¤ID: {target_group_id}, æ—¥æœŸç­›é€‰: {command_parts[2] if len(command_parts) > 2 else 'æ— '}")

        # 2. æƒé™å’Œç™½åå•æ ¡éªŒ
        if user_id not in self.admin_users:
            await event.send(MessageChain([Comp.Plain("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œç¾¤æ–‡ä»¶å¤‡ä»½æ“ä½œçš„æƒé™ã€‚")]))
            return
        
        if self.group_whitelist and target_group_id not in self.group_whitelist:
            await event.send(MessageChain([Comp.Plain("âš ï¸ ç›®æ ‡ç¾¤èŠä¸åœ¨æ’ä»¶é…ç½®çš„ç™½åå•ä¸­ï¼Œæ“ä½œå·²æ‹’ç»ã€‚")]))
            return

        # 3. å¯åŠ¨å¼‚æ­¥å¤‡ä»½ä»»åŠ¡
        self.active_tasks.append(asyncio.create_task(
            self._perform_group_file_backup(event, target_group_id, date_filter_timestamp)
        ))
        event.stop_event()

    async def terminate(self):
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] æ­£åœ¨å¸è½½ï¼Œå–æ¶ˆæ‰€æœ‰ä»»åŠ¡...")

        if self.scheduler and self.scheduler.running:
            try:
                self.scheduler.shutdown(wait=False) 
                logger.info("APScheduler å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²æˆåŠŸåœæ­¢ã€‚")
            except Exception as e:
                logger.error(f"åœæ­¢ APScheduler æ—¶å‘ç”Ÿé”™è¯¯: {e}")

        for task in self.active_tasks:
            if not task.done():
                task.cancel()
        
        try:
            await asyncio.gather(*self.active_tasks, return_exceptions=True)
        except asyncio.CancelledError:
            pass
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²å¸è½½ã€‚")