import os
import asyncio
import time
import subprocess
import aiohttp
import chardet
import pypdfium2 as pdfium
from typing import List, Dict, Optional
from astrbot.api import logger
from astrbot.api.star import StarTools
from aiocqhttp.exceptions import ActionFailed
from . import utils

async def get_preview_from_bytes(content_bytes: bytes) -> tuple[str, str]:
    """ä»å­—èŠ‚å†…å®¹ä¸­å°è¯•è·å–æ–‡æœ¬é¢„è§ˆå’Œç¼–ç ã€‚"""
    try:
        detection = chardet.detect(content_bytes)
        encoding = detection.get('encoding', 'utf-8') or 'utf-8'
        if encoding and detection['confidence'] > 0.7:
            decoded_text = content_bytes.decode(encoding, errors='ignore').strip()
            return decoded_text, encoding
        return "", "æœªçŸ¥"
    except Exception:
        return "", "æœªçŸ¥"

async def get_preview_from_archive(file_path: str, default_zip_password: str, preview_length: int, cleanup_fn, inner_target: str = None) -> tuple[str, str]:
    """ä»æœ¬åœ°å‹ç¼©æ–‡ä»¶ä¸­è§£å‹å¹¶é¢„è§ˆæœ€åˆé€‚çš„æ–‡æœ¬æ–‡ä»¶ã€‚æ”¯æŒå¤šç§æ ¼å¼ã€‚"""
    temp_dir = os.path.join(StarTools.get_data_dir('astrbot_plugin_GroupFS'), 'temp_file_previews')
    os.makedirs(temp_dir, exist_ok=True)
    extract_path = os.path.join(temp_dir, f"extract_{int(time.time())}")
    os.makedirs(extract_path, exist_ok=True)
    
    preview_text = ""
    error_msg = None
    
    try:
        # 1. è§£å‹æ–‡ä»¶
        logger.info(f"æ­£åœ¨å°è¯•æ— å¯†ç è§£å‹æ–‡ä»¶ '{os.path.basename(file_path)}'...")
        command_no_pwd = ["7za", "x", file_path, f"-o{extract_path}", "-y"]
        # å¦‚æœæœ‰æŒ‡å®šå†…éƒ¨è·¯å¾„ï¼ˆéåºå·ï¼‰ï¼Œåªè§£å‹è¯¥æ–‡ä»¶ä»¥æé«˜é€Ÿåº¦
        if inner_target and not inner_target.isdigit():
             command_no_pwd.append(inner_target)

        process = await asyncio.create_subprocess_exec(
            *command_no_pwd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            if default_zip_password:
                logger.info("æ— å¯†ç è§£å‹å¤±è´¥ï¼Œæ­£åœ¨å°è¯•ä½¿ç”¨é»˜è®¤å¯†ç ...")
                command_with_pwd = ["7za", "x", file_path, f"-o{extract_path}", f"-p{default_zip_password}", "-y"]
                if inner_target and not inner_target.isdigit():
                    command_with_pwd.append(inner_target)
                process = await asyncio.create_subprocess_exec(
                    *command_with_pwd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                stdout, stderr = await process.communicate()
                
                if process.returncode != 0:
                    error_msg = stderr.decode('utf-8', errors='ignore').strip()
                    logger.error(f"ä½¿ç”¨é»˜è®¤å¯†ç è§£å‹å¤±è´¥: {error_msg}")
                    error_msg = "è§£å‹å¤±è´¥ï¼Œå¯èƒ½å¯†ç ä¸æ­£ç¡®"
            else:
                error_msg = stderr.decode('utf-8', errors='ignore').strip()
                logger.error(f"ä½¿ç”¨ 7za å‘½ä»¤è§£å‹å¤±è´¥ä¸”æœªè®¾ç½®é»˜è®¤å¯†ç : {error_msg}")
                error_msg = "è§£å‹å¤±è´¥ï¼Œå¯èƒ½æ–‡ä»¶å·²åŠ å¯†"
        
        if error_msg:
            return "", error_msg

        all_extracted_files = []
        for dirpath, _, filenames in os.walk(extract_path):
            for f in filenames:
                f_p = os.path.join(dirpath, f)
                all_extracted_files.append(f_p)
        
        # æ’åºä»¥ä¿è¯åºå·ç¨³å®š
        all_extracted_files.sort()
        
        if not all_extracted_files:
            if inner_target:
                return "", f"å‹ç¼©åŒ…å†…æœªæ‰¾åˆ°æ–‡ä»¶: {inner_target}"
            return "", "å‹ç¼©åŒ…ä¸ºç©ºæˆ–è§£å‹å¤±è´¥"

        # 2. å¯»æ‰¾é¢„è§ˆæ–‡ä»¶
        preview_file_path = None
        
        if inner_target:
            if inner_target.isdigit():
                # æŒ‰åºå·é¢„è§ˆ
                idx = int(inner_target)
                if 1 <= idx <= len(all_extracted_files):
                    preview_file_path = all_extracted_files[idx-1]
                    if not preview_file_path.lower().endswith(utils.SUPPORTED_TEXT_FORMATS):
                        return "", f"âŒ å†…éƒ¨æ–‡ä»¶ #{idx} ä¸æ”¯æŒé¢„è§ˆæ ¼å¼ã€‚"
                else:
                    return "", f"âŒ å†…éƒ¨åºå·é”™è¯¯ï¼æœ‰æ•ˆèŒƒå›´: 1-{len(all_extracted_files)}"
            else:
                # å¯»æ‰¾æœ€æ¥è¿‘çš„æ–‡ä»¶è·¯å¾„
                for f_p in all_extracted_files:
                    if f_p.replace(extract_path, "").strip(os.sep).replace(os.sep, "/") == inner_target.replace(os.sep, "/"):
                        preview_file_path = f_p
                        break
                if not preview_file_path:
                    # æ¨¡ç³ŠåŒ¹é…
                    for f_p in all_extracted_files:
                        if inner_target.lower() in f_p.lower():
                            preview_file_path = f_p
                            break
                if preview_file_path and not preview_file_path.lower().endswith(utils.SUPPORTED_TEXT_FORMATS):
                    return "", f"âŒ æŒ‡å®šçš„æ–‡ä»¶ã€Œ{os.path.basename(preview_file_path)}ã€ä¸æ”¯æŒé¢„è§ˆæ ¼å¼ã€‚"
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®šï¼Œä¸”åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œä¸”è¯¥æ–‡ä»¶æ”¯æŒé¢„è§ˆï¼Œåˆ™è‡ªåŠ¨é¢„è§ˆ
        if not preview_file_path and len(all_extracted_files) == 1:
            first_file = all_extracted_files[0]
            if first_file.lower().endswith(utils.SUPPORTED_TEXT_FORMATS):
                preview_file_path = first_file

        if not preview_file_path:
            # è¾“å‡ºæ–‡ä»¶æ ‘
            file_structure = ["ğŸ“¦ å‹ç¼©åŒ…å†…æ–‡ä»¶ç»“æ„ï¼š"]
            for i, f_path in enumerate(all_extracted_files, 1):
                relative_path = os.path.relpath(f_path, extract_path)
                file_size = os.path.getsize(f_path)
                size_str = utils.format_bytes(file_size)
                # ä½¿ç”¨ / ä½œä¸ºåˆ†éš”ç¬¦ç»Ÿä¸€æ˜¾ç¤º
                display_path = relative_path.replace(os.sep, "/")
                file_structure.append(f"[{i}] {display_path} ({size_str})")
            
            file_structure.append("\nğŸ’¡ æç¤ºï¼šä½¿ç”¨ /é¢„è§ˆ <åºå·> <å†…éƒ¨åºå·> é¢„è§ˆç‰¹å®šæ–‡ä»¶ã€‚")
            structure_text = "\n".join(file_structure)
            return structure_text, None
        
        # 3. è¯»å–å¹¶è§£ç å†…å®¹
        with open(preview_file_path, 'rb') as f:
            content_bytes = f.read(preview_length * 4)
        
        preview_text_raw, encoding = await get_preview_from_bytes(content_bytes)
        
        inner_file_name = os.path.relpath(preview_file_path, extract_path).replace(os.sep, "/")
        preview_text = f"ğŸ“‚ å†…éƒ¨æ–‡ä»¶: {inner_file_name}\n" + "-" * 20 + f"\n{preview_text_raw}"
        
    except FileNotFoundError:
        logger.error("è§£å‹å¤±è´¥ï¼šå®¹å™¨å†…æœªæ‰¾åˆ° 7za å‘½ä»¤ã€‚")
        error_msg = "è§£å‹å¤±è´¥ï¼šæœªå®‰è£… 7za"
    except Exception as e:
        logger.error(f"å¤„ç†å‹ç¼©æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        error_msg = "å¤„ç†å‹ç¼©æ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"
    finally:
        if extract_path and os.path.exists(extract_path):
            try:
                for root, dirs, files in os.walk(extract_path, topdown=False):
                    for name in files:
                        os.remove(os.path.join(root, name))
                    for name in dirs:
                        os.rmdir(os.path.join(root, name))
                os.rmdir(extract_path)
            except Exception as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹ {extract_path} å¤±è´¥: {e}")
    
    return preview_text, error_msg

async def get_pdf_preview(file_path: str, max_pages: int = 1) -> List[str]:
    """ä½¿ç”¨ pypdfium2 ç”Ÿæˆ PDF é¢„è§ˆå›¾"""
    if max_pages <= 0:
        return []
        
    image_paths = []
    temp_dir = os.path.join(StarTools.get_data_dir('astrbot_plugin_GroupFS'), 'temp_file_previews')
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        pdf = pdfium.PdfDocument(file_path)
        num_pages = len(pdf)
        pages_to_render = min(num_pages, max_pages)
        
        for i in range(pages_to_render):
            page = pdf[i]
            # scale=2 å¯¹åº”çº¦ 144 DPI
            bitmap = page.render(scale=2)
            image_path = os.path.join(temp_dir, f"pdf_preview_{int(time.time())}_{i}.png")
            bitmap.to_pil().save(image_path)
            image_paths.append(image_path)
            page.close() # é‡Šæ”¾èµ„æº
        pdf.close() # é‡Šæ”¾èµ„æº
    except Exception as e:
        logger.error(f"ç”Ÿæˆ PDF é¢„è§ˆå¤±è´¥: {e}", exc_info=True)
    return image_paths

async def get_file_preview(group_id: int, file_info: dict, bot, default_zip_password: str, preview_length: int, semaphore: asyncio.Semaphore, cleanup_fn, inner_target: str = None, pdf_preview_pages: int = 1) -> tuple[str, str | None | List[str]]:
    file_id = file_info.get("file_id")
    file_name = file_info.get("file_name", "")
    _, file_extension = os.path.splitext(file_name)
    file_extension = file_extension.lower()
    
    is_txt = file_extension in utils.SUPPORTED_TEXT_FORMATS
    is_archive = file_extension in utils.SUPPORTED_ARCHIVE_FORMATS
    is_pdf = file_extension in utils.SUPPORTED_PDF_FORMATS
    
    if not (is_txt or is_archive or is_pdf):
        return "", f"âŒ æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ˜¯æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œæ— æ³•é¢„è§ˆã€‚"
        
    logger.info(f"[{group_id}] æ­£åœ¨ä¸ºæ–‡ä»¶ '{file_name}' (ID: {file_id}) è·å–é¢„è§ˆ (ç›®æ ‡: {inner_target})...")
    
    local_file_path = None
    
    try:
        url_result = await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
        if not (url_result and url_result.get('url')):
            return "", f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„ä¸‹è½½é“¾æ¥ã€‚"
        url = url_result['url']
    except ActionFailed as e:
        if e.result.get('retcode') == 1200:
            error_message = (
                f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š\n"
                f"è¯¥æ–‡ä»¶å¯èƒ½å·²å¤±æ•ˆã€‚\n"
                f"å»ºè®®ä½¿ç”¨ /åˆ é™¤ {os.path.splitext(file_name)[0]} å°†å…¶åˆ é™¤ã€‚"
            )
            return "", error_message
        else:
            return "", f"âŒ é¢„è§ˆå¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯ï¼š{e.result.get('wording', 'æœªçŸ¥é”™è¯¯')}"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with semaphore:
                range_header = None
                # å¦‚æœæ˜¯å‹ç¼©åŒ…æˆ–æŒ‡å®šäº†å†…éƒ¨è·¯å¾„ï¼Œä¸èƒ½ä½¿ç”¨ Range ä¸‹è½½ï¼Œå› ä¸ºéœ€è¦å®Œæ•´æ–‡ä»¶è¿›è¡Œè§£å‹
                if is_txt and not inner_target:
                    read_bytes_limit = preview_length * 4
                    range_header = {'Range': f'bytes=0-{read_bytes_limit - 1}'}
                async with session.get(url, headers=range_header, timeout=30) as resp:
                    if resp.status != 200 and resp.status != 206:
                        return "", f"âŒ ä¸‹è½½æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ (HTTP: {resp.status})ã€‚"
                    
                    temp_dir = os.path.join(StarTools.get_data_dir('astrbot_plugin_GroupFS'), 'temp_file_previews')
                    os.makedirs(temp_dir, exist_ok=True)
                    local_file_path = os.path.join(temp_dir, f"{file_id}_{file_name}")
                    
                    content_bytes = await resp.read()
                    with open(local_file_path, 'wb') as f:
                        f.write(content_bytes)
        
        preview_content = ""
        error_msg = None
        if is_txt and not inner_target:
            decoded_text, _ = await get_preview_from_bytes(content_bytes)
            if decoded_text:
                preview_content = decoded_text
        elif is_archive:
            preview_text, error_msg = await get_preview_from_archive(local_file_path, default_zip_password, preview_length, cleanup_fn, inner_target)
            if error_msg:
                return "", error_msg
            preview_content = preview_text
        elif is_pdf:
            image_paths = await get_pdf_preview(local_file_path, pdf_preview_pages)
            if not image_paths:
                return "", "âŒ ç”Ÿæˆ PDF é¢„è§ˆå¤±è´¥ã€‚"
            return image_paths, None
        elif is_txt and inner_target:
             return "", f"âŒ æ–‡æœ¬æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ”¯æŒå†…éƒ¨è·¯å¾„é¢„è§ˆã€‚"
        
        is_file_structure = preview_content.startswith("ğŸ“¦ å‹ç¼©åŒ…å†…æ–‡ä»¶ç»“æ„ï¼š")
        if not is_file_structure and len(preview_content) > preview_length:
            preview_content = preview_content[:preview_length] + "..."
        
        logger.info(f"[æ–‡ä»¶é¢„è§ˆ] æ–‡ä»¶: {file_name}, é¢„è§ˆé•¿åº¦: {len(preview_content)}, æ˜¯å¦æ–‡ä»¶ç»“æ„: {is_file_structure}")
        
        return preview_content, None
            
    except asyncio.TimeoutError:
        return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€è¶…æ—¶ã€‚"
    except Exception as e:
        logger.error(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
        return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"
    finally:
        if local_file_path and os.path.exists(local_file_path):
            try:
                os.remove(local_file_path)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {local_file_path}")
            except OSError as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {local_file_path} å¤±è´¥: {e}")
