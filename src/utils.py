# astrbot_plugin_GroupFS/utils.py

import datetime
from datetime import datetime as dt
from typing import Optional, List
from astrbot.api.event import AstrMessageEvent, MessageChain
from astrbot.api import logger
import astrbot.api.message_components as Comp
from astrbot.api.message_components import Plain, Node, Nodes

# --- è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æ–‡ä»¶å¤§å° ---
def format_bytes(size: int, target_unit=None) -> str:
    if size is None: return "æœªçŸ¥å¤§å°"
    power = 1024
    n = 0
    power_labels = {0: 'B', 1: 'KB', 2: 'MB', 3: 'GB', 4: 'TB'}
    if target_unit and target_unit.upper() in power_labels.values():
        target_n = list(power_labels.keys())[list(power_labels.values()).index(target_unit.upper())]
        while n < target_n:
            size /= power
            n += 1
        return f"{size:.2f}"
    while size > power and n < len(power_labels) -1 :
        size /= power
        n += 1
    return f"{size:.2f} {power_labels[n]}"

# --- è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æ—¶é—´æˆ³ ---
def format_timestamp(ts: int) -> str:
    if ts is None or ts == 0: return "æœªçŸ¥æ—¶é—´"
    return datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M')

# --- è¾…åŠ©å‡½æ•°ï¼šè§£ææ—¥æœŸå‚æ•° ---
def parse_date_param(date_str: str) -> Optional[int]:
    """
    è§£ææ—¥æœŸå‚æ•°ï¼Œæ”¯æŒæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD
    è¿”å›æ—¶é—´æˆ³ï¼Œå¤±è´¥è¿”å› None
    """
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        "%Y-%m-%d",
        "%Y%m%d",
        "%Y/%m/%d"
    ]
    
    for fmt in date_formats:
        try:
            parsed_dt = dt.strptime(date_str, fmt)
            return int(parsed_dt.timestamp())
        except ValueError:
            continue
    return None

# --- å¸¸é‡ï¼šå®šä¹‰æ”¯æŒé¢„è§ˆçš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ ---
SUPPORTED_TEXT_FORMATS = (
    '.txt', '.md', '.json', '.xml', '.html', '.css', 
    '.js', '.py', '.java', '.c', '.cpp', '.h', '.hpp', 
    '.go', '.rs', '.rb', '.php', '.log', '.ini', '.yml', '.yaml',
    '.toml', '.conf', '.cfg', '.sh', '.bat', '.ps1', '.sql',
    '.csv', '.tsv', '.env', '.dockerfile', '.gitignore'
)

SUPPORTED_ARCHIVE_FORMATS = (
    '.zip', '.7z', '.tar', '.gz', '.bz2', '.xz',
    '.tar.gz', '.tgz', '.tar.bz2', '.tbz2', '.tar.xz', '.txz',
    '.iso', '.wim', '.rar'
)

# --- è¾…åŠ©å‡½æ•°ï¼šå°†æ–‡æœ¬æŒ‰æŒ‡å®šé•¿åº¦åˆ†å‰² ---
def split_text_by_length(text: str, max_length: int = 1000) -> list[str]:
    """
    å°†æ–‡æœ¬æŒ‰æŒ‡å®šé•¿åº¦åˆ†å‰²æˆä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ã€‚
    """
    return [text[i:i + max_length] for i in range(0, len(text), max_length)]

# --- è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æœç´¢ç»“æœ ---
def format_search_results(files: list[dict], search_term: str, for_delete: bool = False) -> str:
    reply_text = f"ğŸ” æ‰¾åˆ°äº† {len(files)} ä¸ªä¸ã€Œ{search_term}ã€ç›¸å…³çš„ç»“æœï¼š\n"
    reply_text += "-" * 20
    for i, file_info in enumerate(files, 1):
        reply_text += (
            f"\n[{i}] {file_info.get('file_name')}"
            f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
            f"\n  å¤§å°: {format_bytes(file_info.get('size'))}"
            f"\n  ä¿®æ”¹æ—¶é—´: {format_timestamp(file_info.get('modify_time'))}"
        )
    reply_text += "\n" + "-" * 20
    if for_delete:
        reply_text += f"\nè¯·ä½¿ç”¨ /df {search_term} [åºå·] æ¥åˆ é™¤æŒ‡å®šæ–‡ä»¶ã€‚"
    else:
        reply_text += f"\nå¦‚éœ€åˆ é™¤ï¼Œè¯·ä½¿ç”¨ /df {search_term} [åºå·]"
    return reply_text

# --- è¾…åŠ©å‡½æ•°ï¼šå‘é€æ™®é€šæ¶ˆæ¯æˆ–åˆå¹¶è½¬å‘æ¶ˆæ¯ ---
async def send_or_forward(event: AstrMessageEvent, text: str, forward_threshold: int, name: str = "GroupFS"):
    total_length = len(text)
    group_id = event.get_group_id()

    if forward_threshold > 0 and total_length > forward_threshold:
        logger.info(f"[{group_id}] æ£€æµ‹åˆ°é•¿æ¶ˆæ¯ (é•¿åº¦: {total_length} > {forward_threshold})ï¼Œå‡†å¤‡è‡ªåŠ¨åˆå¹¶è½¬å‘ã€‚")
        try:
            split_texts = split_text_by_length(text, 4000)
            forward_nodes = []
            
            logger.info(f"[{group_id}] å°†æ¶ˆæ¯åˆ†å‰²ä¸º {len(split_texts)} ä¸ªèŠ‚ç‚¹ã€‚")
            for i, part_text in enumerate(split_texts):
                node_name = f"{name} ({i+1})" if len(split_texts) > 1 else name
                forward_nodes.append(Node(uin=event.get_self_id(), name=node_name, content=[Plain(part_text)]))

            merged_forward_message = Nodes(nodes=forward_nodes)
            await event.send(MessageChain([merged_forward_message]))
            logger.info(f"[{group_id}] æˆåŠŸå‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ã€‚")

        except Exception as e:
            logger.error(f"[{group_id}] åˆå¹¶è½¬å‘é•¿æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
            
            fallback_text = text[:forward_threshold] + "... (æ¶ˆæ¯è¿‡é•¿ä¸”åˆå¹¶è½¬å‘å¤±è´¥)"
            await event.send(MessageChain([Comp.Plain(fallback_text)]))
            logger.info(f"[{group_id}] åˆå¹¶è½¬å‘å¤±è´¥ï¼Œå·²å›é€€ä¸ºå‘é€æˆªæ–­çš„æ™®é€šæ¶ˆæ¯ã€‚")
    else:
        logger.info(f"[{group_id}] æ¶ˆæ¯é•¿åº¦æœªè¾¾é˜ˆå€¼ ({total_length} <= {forward_threshold})ï¼Œç›´æ¥å‘é€æ™®é€šæ¶ˆæ¯ã€‚")
        try:
            await event.send(MessageChain([Comp.Plain(text)]))
            logger.info(f"[{group_id}] æˆåŠŸå‘é€æ™®é€šæ¶ˆæ¯ã€‚")
        except Exception as e:
            logger.error(f"[{group_id}] å‘é€æ™®é€šæ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)