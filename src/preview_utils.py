import os
import asyncio
import time
import subprocess
import aiohttp
import chardet
from typing import List, Dict, Optional
from astrbot.api import logger
from astrbot.api.star import StarTools
from aiocqhttp.exceptions import ActionFailed
from . import utils

async def get_preview_from_bytes(content_bytes: bytes) -> tuple[str, str]:
    """ä»å­—èŠ‚å†…å®¹ä¸­å°è¯•è·å–æ–‡æœ¬é¢„è§ˆå’Œç¼–ç ã€‚"""
    try:
        detection = chardet.detect(content_bytes)
        encoding = detection.get('encoding', 'utf-8') or 'utf-8'
        if encoding and detection['confidence'] > 0.7:
            decoded_text = content_bytes.decode(encoding, errors='ignore').strip()
            return decoded_text, encoding
        return "", "æœªçŸ¥"
    except Exception:
        return "", "æœªçŸ¥"

async def get_preview_from_zip(file_path: str, default_zip_password: str, preview_length: int, cleanup_fn) -> tuple[str, str]:
    """ä»æœ¬åœ°å‹ç¼©æ–‡ä»¶ä¸­è§£å‹å¹¶é¢„è§ˆç¬¬ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ã€‚è¿”å› (é¢„è§ˆå†…å®¹, é”™è¯¯ä¿¡æ¯)ã€‚"""
    temp_dir = os.path.join(StarTools.get_data_dir('astrbot_plugin_GroupFS'), 'temp_file_previews')
    os.makedirs(temp_dir, exist_ok=True)
    extract_path = os.path.join(temp_dir, f"extract_{int(time.time())}")
    os.makedirs(extract_path, exist_ok=True)
    
    preview_text = ""
    error_msg = None
    
    try:
        logger.info(f"æ­£åœ¨å°è¯•æ— å¯†ç è§£å‹æ–‡ä»¶ '{os.path.basename(file_path)}'...")
        command_no_pwd = ["7za", "x", file_path, f"-o{extract_path}", "-y"]
        process = await asyncio.create_subprocess_exec(
            *command_no_pwd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            if default_zip_password:
                logger.info("æ— å¯†ç è§£å‹å¤±è´¥ï¼Œæ­£åœ¨å°è¯•ä½¿ç”¨é»˜è®¤å¯†ç ...")
                command_with_pwd = ["7za", "x", file_path, f"-o{extract_path}", f"-p{default_zip_password}", "-y"]
                process = await asyncio.create_subprocess_exec(
                    *command_with_pwd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                stdout, stderr = await process.communicate()
                
                if process.returncode != 0:
                    error_msg = stderr.decode('utf-8').strip()
                    logger.error(f"ä½¿ç”¨é»˜è®¤å¯†ç è§£å‹å¤±è´¥: {error_msg}")
                    error_msg = "è§£å‹å¤±è´¥ï¼Œå¯èƒ½å¯†ç ä¸æ­£ç¡®"
            else:
                error_msg = stderr.decode('utf-8').strip()
                logger.error(f"ä½¿ç”¨ 7za å‘½ä»¤è§£å‹å¤±è´¥ä¸”æœªè®¾ç½®é»˜è®¤å¯†ç : {error_msg}")
                error_msg = "è§£å‹å¤±è´¥ï¼Œå¯èƒ½æ–‡ä»¶å·²åŠ å¯†"
        
        if error_msg:
            return "", error_msg

        all_extracted_files = [os.path.join(dirpath, f) for dirpath, _, filenames in os.walk(extract_path) for f in filenames]
        preview_file_path = None
        
        for f_path in all_extracted_files:
            if f_path.lower().endswith('.txt'):
                preview_file_path = f_path
                break
        
        if not preview_file_path:
            if not all_extracted_files:
                return "", "å‹ç¼©åŒ…ä¸ºç©ºæˆ–è§£å‹å¤±è´¥"
            
            file_structure = ["ğŸ“¦ å‹ç¼©åŒ…å†…æ–‡ä»¶ç»“æ„ï¼š"]
            for f_path in sorted(all_extracted_files):
                relative_path = os.path.relpath(f_path, extract_path)
                file_size = os.path.getsize(f_path)
                size_str = utils.format_bytes(file_size)
                depth = relative_path.count(os.sep)
                indent = "  " * depth
                file_name = os.path.basename(relative_path)
                file_structure.append(f"{indent}â”œâ”€ {file_name} ({size_str})")
            
            structure_text = "\n".join(file_structure)
            return structure_text, None
        
        with open(preview_file_path, 'rb') as f:
            content_bytes = f.read(preview_length * 4)
        
        preview_text_raw, encoding = await get_preview_from_bytes(content_bytes)
        
        inner_file_name = os.path.relpath(preview_file_path, extract_path)
        extra_info = f"å·²è§£å‹ã€Œ{inner_file_name}ã€(æ ¼å¼ {encoding})"
        preview_text = f"{extra_info}\n{preview_text_raw}"
        
    except FileNotFoundError:
        logger.error("è§£å‹å¤±è´¥ï¼šå®¹å™¨å†…æœªæ‰¾åˆ° 7za å‘½ä»¤ã€‚")
        error_msg = "è§£å‹å¤±è´¥ï¼šæœªå®‰è£… 7za"
    except Exception as e:
        logger.error(f"å¤„ç†ZIPæ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        error_msg = "å¤„ç†å‹ç¼©æ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"
    finally:
        if os.path.exists(extract_path):
            asyncio.create_task(cleanup_fn(extract_path))
    
    return preview_text, error_msg

async def get_file_preview(group_id: int, file_info: dict, bot, enable_zip_preview: bool, default_zip_password: str, preview_length: int, semaphore: asyncio.Semaphore, cleanup_fn) -> tuple[str, str | None]:
    file_id = file_info.get("file_id")
    file_name = file_info.get("file_name", "")
    _, file_extension = os.path.splitext(file_name)
    
    is_txt = file_extension.lower() == '.txt'
    is_zip = enable_zip_preview and file_extension.lower() == '.zip'
    
    if not (is_txt or is_zip):
        return "", f"âŒ æ–‡ä»¶ã€Œ{file_name}ã€ä¸æ˜¯æ”¯æŒçš„æ–‡æœ¬æˆ–å‹ç¼©æ ¼å¼ï¼Œæ— æ³•é¢„è§ˆã€‚"
        
    logger.info(f"[{group_id}] æ­£åœ¨ä¸ºæ–‡ä»¶ '{file_name}' (ID: {file_id}) è·å–é¢„è§ˆ...")
    
    local_file_path = None
    
    try:
        url_result = await bot.api.call_action('get_group_file_url', group_id=group_id, file_id=file_id)
        if not (url_result and url_result.get('url')):
            return "", f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„ä¸‹è½½é“¾æ¥ã€‚"
        url = url_result['url']
    except ActionFailed as e:
        if e.result.get('retcode') == 1200:
            error_message = (
                f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š\n"
                f"è¯¥æ–‡ä»¶å¯èƒ½å·²å¤±æ•ˆã€‚\n"
                f"å»ºè®®ä½¿ç”¨ /df {os.path.splitext(file_name)[0]} å°†å…¶åˆ é™¤ã€‚"
            )
            return "", error_message
        else:
            return "", f"âŒ é¢„è§ˆå¤±è´¥ï¼ŒAPIè¿”å›é”™è¯¯ï¼š{e.result.get('wording', 'æœªçŸ¥é”™è¯¯')}"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with semaphore:
                range_header = None
                if is_txt:
                    read_bytes_limit = preview_length * 4
                    range_header = {'Range': f'bytes=0-{read_bytes_limit - 1}'}
                async with session.get(url, headers=range_header, timeout=30) as resp:
                    if resp.status != 200 and resp.status != 206:
                        return "", f"âŒ ä¸‹è½½æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ (HTTP: {resp.status})ã€‚"
                    
                    temp_dir = os.path.join(StarTools.get_data_dir('astrbot_plugin_GroupFS'), 'temp_file_previews')
                    os.makedirs(temp_dir, exist_ok=True)
                    local_file_path = os.path.join(temp_dir, f"{file_id}_{file_name}")
                    
                    content_bytes = await resp.read()
                    with open(local_file_path, 'wb') as f:
                        f.write(content_bytes)
        
        preview_content = ""
        error_msg = None
        if is_txt:
            decoded_text, _ = await get_preview_from_bytes(content_bytes)
            preview_content = decoded_text
        elif is_zip:
            preview_text, error_msg = await get_preview_from_zip(local_file_path, default_zip_password, preview_length, cleanup_fn)
            if error_msg:
                return "", error_msg
            preview_content = preview_text
        
        is_file_structure = preview_content.startswith("ğŸ“¦ å‹ç¼©åŒ…å†…æ–‡ä»¶ç»“æ„ï¼š")
        if not is_file_structure and len(preview_content) > preview_length:
            preview_content = preview_content[:preview_length] + "..."
        
        logger.info(f"[æ–‡ä»¶é¢„è§ˆ] æ–‡ä»¶: {file_name}, é¢„è§ˆé•¿åº¦: {len(preview_content)}, æ˜¯å¦æ–‡ä»¶ç»“æ„: {is_file_structure}")
        
        return preview_content, None
            
    except asyncio.TimeoutError:
        return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€è¶…æ—¶ã€‚"
    except Exception as e:
        logger.error(f"[{group_id}] è·å–æ–‡ä»¶ '{file_name}' é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
        return "", f"âŒ é¢„è§ˆæ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"
    finally:
        if local_file_path and os.path.exists(local_file_path):
            try:
                os.remove(local_file_path)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {local_file_path}")
            except OSError as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {local_file_path} å¤±è´¥: {e}")
