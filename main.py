import asyncio
import os
from typing import List, Dict, Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler

import croniter

from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger
import astrbot.api.message_components as Comp
from aiocqhttp.exceptions import ActionFailed 

from .src import utils
from .src.file_ops import (
    get_all_files_with_path, 
    download_and_save_file, 
    create_zip_archive, 
    cleanup_folder, 
    cleanup_backup_temp,
    get_all_files_recursive_core,
    rename_group_file
)
from .src.preview_utils import get_file_preview
from .src.actions import (
    perform_scheduled_check, 
    perform_batch_check_and_delete,
    perform_batch_delete,
    check_storage_and_notify
)
from .src.backup import perform_group_file_backup
from .src.duplicate_check import detect_duplicates
from .src.session_manager import SessionManager


@register(
    "astrbot_plugin_GroupFS",
    "Foolllll",
    "ç®¡ç†QQç¾¤æ–‡ä»¶",
    "1.0",
    "https://github.com/Foolllll-J/astrbot_plugin_GroupFS"
)
class GroupFSPlugin(Star):
    def __init__(self, context: Context, config: Optional[Dict] = None):
        super().__init__(context)
        self.config = config if config else {}
        self.group_whitelist: List[int] = [int(g) for g in self.config.get("group_whitelist", [])]
        self.admin_users: List[int] = [int(u) for u in self.config.get("admin_users", [])]
        self.preview_length: int = self.config.get("preview_length", 300)
        self.storage_limits: Dict[int, Dict] = {}
        self.cron_configs = []
        self.bot = None
        self.scheduler: Optional[AsyncIOScheduler] = None
        
        self.active_tasks = [] 
        
        self.default_zip_password: str = self.config.get("default_zip_password", "")
        self.download_semaphore = asyncio.Semaphore(5)
        
        self.scheduled_autodelete: bool = self.config.get("scheduled_autodelete", False)

        limit_configs = self.config.get("storage_limits", [])
        for item in limit_configs:
            try:
                group_id_str, count_limit_str, space_limit_str = item.split(':')
                group_id = int(group_id_str)
                self.storage_limits[group_id] = { "count_limit": int(count_limit_str), "space_limit_gb": float(space_limit_str) }
            except ValueError as e:
                logger.error(f"è§£æ storage_limits é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        self.backup_zip_password: str = self.config.get("backup_zip_password", "")
        self.backup_file_size_limit_mb: int = self.config.get("backup_file_size_limit_mb", 0)
        ext_str: str = self.config.get("backup_file_extensions", "txt,zip")
        
        self.backup_file_extensions: List[str] = [
            ext.strip().lstrip('.').lower()
            for ext in ext_str.split(',') 
            if ext.strip()
        ]

        # æœç´¢ä¼šè¯ç®¡ç†
        self.search_cache_timeout = 600 # 10åˆ†é’Ÿ
        self.search_results_per_page = 20
        self.session_mgr = SessionManager(timeout=self.search_cache_timeout)

        cron_configs = self.config.get("scheduled_check_tasks", [])
        seen_tasks = set()
        for item in cron_configs:
            try:
                group_id_str, cron_str = item.split(':', 1)
                group_id = int(group_id_str)
                if not croniter.croniter.is_valid(cron_str):
                    raise ValueError(f"æ— æ•ˆçš„ cron è¡¨è¾¾å¼: {cron_str}")
                
                task_identifier = (group_id, cron_str)
                if task_identifier in seen_tasks:
                    logger.warning(f"æ£€æµ‹åˆ°é‡å¤çš„å®šæ—¶ä»»åŠ¡é…ç½® '{item}'ï¼Œå·²è·³è¿‡ã€‚")
                    continue
                
                self.cron_configs.append({"group_id": group_id, "cron_str": cron_str})
                seen_tasks.add(task_identifier)
            except ValueError as e:
                logger.error(f"è§£æ scheduled_check_tasks é…ç½® '{item}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²åŠ è½½ã€‚")

    async def initialize(self):
        # å°è¯•ä» platform_manager è‡ªåŠ¨è·å– bot å®ä¾‹
        if hasattr(self.context, "platform_manager"):
            try:
                platforms = self.context.platform_manager.get_insts()
                for platform in platforms:
                    bot_client = None
                    if hasattr(platform, "get_client"):
                        bot_client = platform.get_client()
                    elif hasattr(platform, "bot"):
                        bot_client = platform.bot
                    
                    if bot_client:
                        self.bot = bot_client
                        logger.info(f"[åˆå§‹åŒ–] æˆåŠŸä» platform_manager è·å– bot å®ä¾‹")
                        break
            except Exception as e:
                logger.warning(f"[åˆå§‹åŒ–] ä» platform_manager è·å– bot å®ä¾‹å¤±è´¥: {e}")
        
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡
        if self.cron_configs:
            if self.bot:
                # å¦‚æœå·²ç»è·å–åˆ° botï¼Œç›´æ¥å¯åŠ¨è°ƒåº¦å™¨ï¼Œä¸éœ€è¦ç­‰å¾… 30 ç§’
                logger.info("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥è°ƒåº¦å™¨...")
                self.scheduler = AsyncIOScheduler()
                self._register_jobs()
                self.scheduler.start()
            else:
                # åªæœ‰åœ¨æ²¡è·å–åˆ° bot çš„æƒ…å†µä¸‹ï¼Œæ‰è¿›å…¥å»¶è¿Ÿå¯åŠ¨æµç¨‹
                logger.warning("[åˆå§‹åŒ–] æœªèƒ½ç«‹å³è·å– bot å®ä¾‹ï¼Œå°†é€šè¿‡å»¶è¿Ÿä»»åŠ¡æ•è·å¹¶å¯åŠ¨è°ƒåº¦å™¨ã€‚")
                asyncio.create_task(self._delayed_start_scheduler())

    async def _delayed_start_scheduler(self):
        """å»¶è¿Ÿå¯åŠ¨è°ƒåº¦å™¨ï¼Œç­‰å¾…ç³»ç»Ÿåˆå§‹åŒ–å¹¶å°è¯•å†æ¬¡è·å– bot"""
        try:
            # ç­‰å¾… 30 ç§’è®©ç³»ç»Ÿå®Œå…¨åˆå§‹åŒ–
            await asyncio.sleep(30)
            
            # å†æ¬¡å°è¯•è·å– bot
            if not self.bot and hasattr(self.context, "platform_manager"):
                platforms = self.context.platform_manager.get_insts()
                for platform in platforms:
                    bot_client = None
                    if hasattr(platform, "get_client"):
                        bot_client = platform.get_client()
                    elif hasattr(platform, "bot"):
                        bot_client = platform.bot
                    
                    if bot_client:
                        self.bot = bot_client
                        logger.info("[å®šæ—¶ä»»åŠ¡] å»¶è¿Ÿå¯åŠ¨è¿‡ç¨‹ä¸­æˆåŠŸè¡¥è· bot å®ä¾‹")
                        break
            
            # å¯åŠ¨è°ƒåº¦å™¨
            if not self.scheduler:
                logger.info("[å®šæ—¶ä»»åŠ¡] å»¶è¿Ÿå¯åŠ¨è°ƒåº¦å™¨...")
                self.scheduler = AsyncIOScheduler()
                self._register_jobs()
                self.scheduler.start()
            
            if not self.bot:
                logger.warning("[å®šæ—¶ä»»åŠ¡] è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œä½†å°šæœªè·å–åˆ° bot å®ä¾‹ã€‚")
                
        except Exception as e:
            logger.error(f"[å®šæ—¶ä»»åŠ¡] å»¶è¿Ÿå¯åŠ¨å¤±è´¥: {e}", exc_info=True)

    def _register_jobs(self):
        """æ ¹æ®é…ç½®æ³¨å†Œå®šæ—¶ä»»åŠ¡"""
        for job_config in self.cron_configs:
            group_id = job_config["group_id"]
            cron_str = job_config["cron_str"]
            job_id = f"scheduled_check_{group_id}_{cron_str.replace(' ', '_')}"
            
            if self.scheduler.get_job(job_id):
                logger.warning(f"ä»»åŠ¡ {job_id} å·²å­˜åœ¨ï¼Œè·³è¿‡æ³¨å†Œã€‚")
                continue
            
            try:
                cron_parts = cron_str.split()
                minute, hour, day, month, day_of_week = cron_parts
                
                self.scheduler.add_job(
                    self._apscheduler_check_task,
                    "cron",
                    args=[group_id, self.scheduled_autodelete],
                    minute=minute,
                    hour=hour,
                    day=day,
                    month=month,
                    day_of_week=day_of_week,
                    id=job_id
                )
                logger.info(f"æˆåŠŸæ³¨å†Œå®šæ—¶ä»»åŠ¡: group_id={group_id}, cron_str='{cron_str}'")
            except Exception as e:
                logger.error(f"æ³¨å†Œå®šæ—¶ä»»åŠ¡ '{cron_str}' å¤±è´¥: {e}", exc_info=True)

    async def _apscheduler_check_task(self, group_id: int, auto_delete: bool):
        """APScheduler è°ƒç”¨çš„åŒ…è£…å‡½æ•°ï¼Œè´Ÿè´£æ¶ˆè´¹ç”Ÿæˆå™¨å¹¶å‘é€æ¶ˆæ¯"""
        if not self.bot:
            logger.warning(f"[{group_id}] [å®šæ—¶ä»»åŠ¡] æ— æ³•æ‰§è¡Œï¼Œå› ä¸ºå°šæœªæ•è·åˆ° bot å®ä¾‹ã€‚")
            return

        async for msg in perform_scheduled_check(group_id, auto_delete, self.bot, self.storage_limits, self.scheduled_autodelete):
            if self.bot:
                await self.bot.api.call_action('send_group_msg', group_id=group_id, message=msg)

    async def _perform_scheduled_check(self, group_id: int, auto_delete: bool):
        async for res in perform_scheduled_check(group_id, auto_delete, self.bot, self.storage_limits, self.scheduled_autodelete):
            yield res


    async def _get_all_files_with_path(self, group_id: int, bot) -> List[Dict]:
        return await get_all_files_with_path(group_id, bot)
    
    async def _get_all_files_recursive_core(self, group_id: int, bot) -> List[Dict]:
        """
        å…¼å®¹ /cdf, /cf, /sf, /df ç­‰æŒ‡ä»¤ã€‚
        """
        return await get_all_files_recursive_core(group_id, bot)
    
    async def _download_and_save_file(self, group_id: int, file_id: str, file_name: str, file_size: int, relative_path: str, root_dir: str, client) -> bool:
        return await download_and_save_file(group_id, file_id, file_name, file_size, relative_path, root_dir, client, self.download_semaphore)

    async def _cleanup_backup_temp(self, backup_dir: str, zip_path: Optional[str]):
        await cleanup_backup_temp(backup_dir, zip_path)

    @filter.command("cdf", alias={"æ¸…ç†å¤±æ•ˆæ–‡ä»¶","æ¸…ç†å¤±æ•ˆç¾¤æ–‡ä»¶"})
    async def on_check_and_delete_command(self, event: AstrMessageEvent):
        """æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cdf å¤±æ•ˆæ–‡ä»¶æ¸…ç†æŒ‡ä»¤ã€‚")
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")
            return
        yield event.plain_result("âš ï¸ è­¦å‘Šï¼šå³å°†å¼€å§‹æ‰«æå¹¶è‡ªåŠ¨åˆ é™¤æ‰€æœ‰å¤±æ•ˆæ–‡ä»¶ï¼\næ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼Œå®Œæˆåå°†å‘é€æŠ¥å‘Šã€‚")
        async for res in perform_batch_check_and_delete(event):
            yield res

    @filter.command("cf", alias={"æ£€æŸ¥ç¾¤æ–‡ä»¶"})
    async def on_check_files_command(self, event: AstrMessageEvent):
        """æ‰«æå¹¶æŸ¥æ‰¾ç¾¤å†…çš„å¤±æ•ˆæ–‡ä»¶ï¼ˆä»…æ£€æŸ¥ä¸åˆ é™¤ï¼‰"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")
            return
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /cf å¤±æ•ˆæ–‡ä»¶æ£€æŸ¥æŒ‡ä»¤ã€‚")
        yield event.plain_result("âœ… å·²å¼€å§‹æ‰«æç¾¤å†…æ‰€æœ‰æ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¤±æ•ˆæ–‡ä»¶...\nè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚\nå¦‚æœæœªå‘ç°å¤±æ•ˆæ–‡ä»¶ï¼Œå°†ä¸ä¼šå‘é€ä»»ä½•æ¶ˆæ¯ã€‚")
        async for res in self._perform_scheduled_check(group_id, False):
            if isinstance(res, str):
                yield event.plain_result(res)
            else:
                yield res
    
    @filter.event_message_type(filter.EventMessageType.GROUP_MESSAGE, priority=10)
    async def on_group_file_upload(self, event: AstrMessageEvent):
        """ç›‘æ§ç¾¤æ–‡ä»¶ä¸Šä¼ äº‹ä»¶"""
        if not self.bot: self.bot = event.bot
        file_component = next((seg for seg in event.get_messages() if isinstance(seg, Comp.File)), None)
        if file_component:
            group_id = int(event.get_group_id())
            
            # ä»…åœ¨é…ç½®äº†å®¹é‡æ£€æŸ¥çš„ç¾¤ç»„ä¸­è§¦å‘
            if group_id not in self.storage_limits:
                return

            file_id = getattr(file_component, 'file_id', None)
            file_name = getattr(file_component, 'file_name', None) or getattr(file_component, 'name', None)
            
            logger.info(f"[{group_id}] æ£€æµ‹åˆ°æ–‡ä»¶ä¸Šä¼ äº‹ä»¶: {file_name} ({file_id})ï¼Œå°†åœ¨5ç§’åè§¦å‘å®¹é‡æ£€æŸ¥ã€‚")
            await asyncio.sleep(5)
            async for res in self._check_storage_and_notify(event):
                yield res

    async def _check_storage_and_notify(self, event: AstrMessageEvent):
        async for res in check_storage_and_notify(event, self.storage_limits):
            yield res
    
    def _format_search_results(self, files: List[Dict], search_term: str, for_delete: bool = False) -> str:
        return utils.format_search_results(files, search_term, for_delete)
    
    @filter.command("sf", alias={"æœç´¢"})
    async def on_search_file_command(self, event: AstrMessageEvent):
        """æœç´¢ç¾¤æ–‡ä»¶"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split()
        
        if len(command_parts) < 2:
            yield event.plain_result("â“ è¯·æä¾›è¦æœç´¢çš„æ–‡ä»¶åã€‚ç”¨æ³•: /æœç´¢ <æ–‡ä»¶å> [åºå·]")
            return
            
        action = command_parts[1].lower()
        session = self.session_mgr.get_session(group_id, user_id)

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¿»é¡µæŒ‡ä»¤
        if action in ['n', 'next', 'ä¸‹ä¸€é¡µ']:
            if session:
                async for res in self._show_search_page(event, session, session.current_page + 1):
                    yield res
                return
            else:
                yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œæœç´¢ã€‚")
                return
        elif action in ['p', 'prev', 'ä¸Šä¸€é¡µ']:
            if session:
                async for res in self._show_search_page(event, session, max(1, session.current_page - 1)):
                    yield res
                return
            else:
                yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œæœç´¢ã€‚")
                return
        elif action in ['page', 'è·³è½¬'] and len(command_parts) > 2:
            if session:
                try:
                    target_page = int(command_parts[2])
                    async for res in self._show_search_page(event, session, target_page):
                        yield res
                    return
                except ValueError:
                    pass
            else:
                yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œæœç´¢ã€‚")
                return
        elif action.isdigit() and not session:
             # å¦‚æœç”¨æˆ·ç›´æ¥è¾“å…¥ /sf 1 ä½†æ²¡æœ‰ä¼šè¯ï¼Œæç¤ºæœç´¢
             yield event.plain_result("âŒ è¯·å…ˆè¾“å…¥æ–‡ä»¶åè¿›è¡Œæœç´¢ã€‚")
             return
        elif action.isdigit() and session:
            # å¦‚æœè¾“å…¥çš„æ˜¯æ•°å­—ä¸”æœ‰ä¼šè¯ï¼Œæ‰§è¡Œè·³è½¬é¡µé¢
            async for res in self._show_search_page(event, session, int(action)):
                yield res
            return

        filename_to_find = command_parts[1]
        index_str = command_parts[2] if len(command_parts) > 2 else None
        
        logger.info(f"[{group_id}] ç”¨æˆ· {user_id} è§¦å‘ /sf, ç›®æ ‡: '{filename_to_find}', åºå·: {index_str}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰ä¼šè¯ä¸”å…³é”®è¯åŒ¹é…
        session = self.session_mgr.get_session(group_id, user_id)
        if session and session.keyword == filename_to_find and index_str:
            # å¦‚æœæœ‰åºå·ä¸”å…³é”®è¯åŒ¹é…ï¼Œç›´æ¥ä»ä¼šè¯ä¸­å–æ–‡ä»¶é¢„è§ˆ
            try:
                index = int(index_str)
                if 1 <= index <= session.total_count:
                    file_to_preview = session.results[index - 1]
                    async for res in self._handle_preview(event, file_to_preview):
                        yield res
                    return
            except ValueError:
                pass

        # é‡æ–°æœç´¢
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = []
        for file_info in all_files:
            current_filename = file_info.get('file_name', '')
            base_name, _ = os.path.splitext(current_filename)
            if filename_to_find in base_name or filename_to_find in current_filename:
                found_files.append(file_info)
        
        logger.info(f"[{group_id}] åœ¨ {len(all_files)} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…é¡¹ã€‚")

        if not found_files:
            yield event.plain_result(f"âŒ æœªåœ¨ç¾¤æ–‡ä»¶ä¸­æ‰¾åˆ°ä¸ã€Œ{filename_to_find}ã€ç›¸å…³çš„ä»»ä½•æ–‡ä»¶ã€‚")
            return
            
        # åˆ›å»ºæ–°ä¼šè¯
        session = self.session_mgr.create_session(group_id, user_id, filename_to_find, found_files, self.search_results_per_page)
        
        if index_str:
            try:
                index = int(index_str)
                if 1 <= index <= len(found_files):
                    file_to_preview = found_files[index - 1]
                    async for res in self._handle_preview(event, file_to_preview):
                        yield res
                    return
                else:
                    yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼æ‰¾åˆ°äº† {len(found_files)} ä¸ªæ–‡ä»¶ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(found_files)} ä¹‹é—´çš„æ•°å­—ã€‚")
                    return
            except ValueError:
                yield event.plain_result("âŒ åºå·å¿…é¡»æ˜¯ä¸€ä¸ªæ•°å­—ã€‚")
                return
        
        # æ˜¾ç¤ºç¬¬ä¸€é¡µ
        async for res in self._show_search_page(event, session, 1):
            yield res

    async def _show_search_page(self, event: AstrMessageEvent, session, page: int):
        total_pages = (session.total_count + session.page_size - 1) // session.page_size
        if page > total_pages:
            yield event.plain_result("âš ï¸ å·²ç»æ˜¯æœ€åä¸€é¡µäº†ã€‚")
            return
        
        session.current_page = page
        results = session.get_page_results(page)
        
        reply_text = f"ğŸ” æ‰¾åˆ°äº† {session.total_count} ä¸ªä¸ã€Œ{session.keyword}ã€ç›¸å…³çš„ç»“æœ (ç¬¬ {page}/{total_pages} é¡µ)ï¼š\n"
        reply_text += "-" * 20
        
        start_idx = (page - 1) * session.page_size + 1
        for i, file_info in enumerate(results, start_idx):
            parent_folder = file_info.get('parent_folder_name', 'æ ¹ç›®å½•')
            path_display = f"\n  è·¯å¾„: {parent_folder}/" if parent_folder != 'æ ¹ç›®å½•' else ""
            
            reply_text += (
                f"\n[{i}] {file_info.get('file_name')}"
                f"{path_display}"
                f"\n  ä¸Šä¼ è€…: {file_info.get('uploader_name', 'æœªçŸ¥')}"
                f"\n  å¤§å°: {utils.format_bytes(file_info.get('size'))}"
                f"\n  ä¿®æ”¹æ—¶é—´: {utils.format_timestamp(file_info.get('modify_time'))}"
            )
        
        reply_text += "\n" + "-" * 20
        if page < total_pages:
            reply_text += f"\nè¾“å…¥ /sf ä¸‹ä¸€é¡µ æŸ¥çœ‹ä¸‹ä¸€é¡µ"
        if page > 1:
            reply_text += f"\nè¾“å…¥ /sf ä¸Šä¸€é¡µ æŸ¥çœ‹ä¸Šä¸€é¡µ"
        reply_text += f"\nè¾“å…¥ /sf è·³è½¬ <é¡µç > è·³è½¬"
        reply_text += f"\n\nğŸ’¡ å¿«é€Ÿæ“ä½œï¼š"
        reply_text += f"\nâ€¢ /é¢„è§ˆ <åºå·> - é¢„è§ˆæ–‡ä»¶"
        reply_text += f"\nâ€¢ /åˆ é™¤ <åºå·> - åˆ é™¤æ–‡ä»¶"
        
        yield event.plain_result(reply_text)

    async def _handle_preview(self, event: AstrMessageEvent, file_to_preview: dict, inner_path: str = None):
        group_id = int(event.get_group_id())
        try:
            preview_text, error_msg = await self._get_file_preview(event, file_to_preview, inner_path)
            if error_msg:
                yield event.plain_result(error_msg)
                return
            
            title = f"ğŸ“„ æ–‡ä»¶ã€Œ{file_to_preview.get('file_name')}ã€å†…å®¹é¢„è§ˆ"
            if inner_path:
                title += f" (å†…éƒ¨è·¯å¾„: {inner_path})"
            
            reply_text = (
                f"{title}ï¼š\n"
                + "-" * 20 + "\n"
                + preview_text
            )
            yield event.plain_result(reply_text)
        except Exception as e:
            logger.error(f"[{group_id}] å¤„ç†é¢„è§ˆæ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}", exc_info=True)
            yield event.plain_result("âŒ é¢„è§ˆæ–‡ä»¶æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")

    @filter.command("preview", alias={"é¢„è§ˆ"})
    async def on_preview_command(self, event: AstrMessageEvent):
        """é¢„è§ˆç¾¤æ–‡ä»¶å†…å®¹"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split()
        
        # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ–‡ä»¶
        quoted_file = await self._resolve_file_from_message(event)

        if len(command_parts) < 2:
            if quoted_file:
                # å¼•ç”¨é¢„è§ˆï¼š/é¢„è§ˆ
                async for res in self._handle_preview(event, quoted_file):
                    yield res
                return
            yield event.plain_result("â“ ç”¨æ³•: /é¢„è§ˆ <åºå·> [å†…éƒ¨åºå·] æˆ– /é¢„è§ˆ <æ–‡ä»¶å> [åºå·] [å†…éƒ¨åºå·] æˆ– å¼•ç”¨æ–‡ä»¶æ¶ˆæ¯åè¾“å…¥ /é¢„è§ˆ")
            return
            
        arg1 = command_parts[1]
        arg2 = command_parts[2] if len(command_parts) > 2 else None
        session = self.session_mgr.get_session(group_id, user_id)
        
        # åœºæ™¯ 0: å¼•ç”¨é¢„è§ˆä¸”å¸¦å†…éƒ¨è·¯å¾„/åºå·ï¼šå¼•ç”¨æ–‡ä»¶åè¾“å…¥ /é¢„è§ˆ 1
        if quoted_file and arg1:
            # å¦‚æœ arg1 æ˜¯æ•°å­—ä¸”ä¸æ˜¯æ–‡ä»¶åï¼Œå°è¯•ä½œä¸ºå†…éƒ¨è·¯å¾„é¢„è§ˆ
            async for res in self._handle_preview(event, quoted_file, arg1):
                yield res
            return

        # åœºæ™¯ 1: /é¢„è§ˆ <åºå·> [å†…éƒ¨è·¯å¾„/åºå·]
        if arg1.isdigit():
            if not session:
                yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œ /æœç´¢ æœç´¢æ–‡ä»¶ã€‚")
                return
            index = int(arg1)
            if 1 <= index <= session.total_count:
                file_to_preview = session.results[index - 1]
                inner_path = arg2
                async for res in self._handle_preview(event, file_to_preview, inner_path):
                    yield res
            else:
                yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼æœ‰æ•ˆèŒƒå›´: 1-{session.total_count}")
            return
            
        # åœºæ™¯ 2: /preview <æ–‡ä»¶å> [åºå·] [å†…éƒ¨è·¯å¾„]
        filename_to_find = arg1
        
        # æœç´¢æ–‡ä»¶
        all_files = await self._get_all_files_recursive_core(group_id, event.bot)
        found_files = [f for f in all_files if filename_to_find in f.get('file_name', '')]
        
        if not found_files:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶ã€Œ{filename_to_find}ã€ã€‚")
            return
            
        file_to_preview = None
        inner_path = None

        if arg2 and arg2.isdigit():
            # /preview <æ–‡ä»¶å> <åºå·> [å†…éƒ¨è·¯å¾„]
            idx = int(arg2)
            if 1 <= idx <= len(found_files):
                file_to_preview = found_files[idx-1]
                inner_path = command_parts[3] if len(command_parts) > 3 else None
            else:
                yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼å…±æ‰¾åˆ° {len(found_files)} ä¸ªåŒ¹é…æ–‡ä»¶ã€‚")
                return
        else:
            # /preview <æ–‡ä»¶å> [å†…éƒ¨è·¯å¾„]
            if len(found_files) == 1:
                file_to_preview = found_files[0]
                inner_path = arg2
            else:
                # å¤šä¸ªç»“æœï¼Œæ›´æ–°ä¼šè¯å¹¶æ˜¾ç¤º
                session = self.session_mgr.create_session(group_id, user_id, filename_to_find, found_files, 20)
                async for res in self._show_search_page(event, session, 1):
                    yield res
                return

        if file_to_preview:
            async for res in self._handle_preview(event, file_to_preview, inner_path):
                yield res

    @filter.command("df", alias={"åˆ é™¤"})
    async def on_delete_file_command(self, event: AstrMessageEvent):
        """åˆ é™¤æŒ‡å®šçš„ç¾¤æ–‡ä»¶"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split()
        
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")
            return

        # æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ–‡ä»¶
        quoted_file = await self._resolve_file_from_message(event)
        
        if len(command_parts) < 2:
            if quoted_file:
                async for res in self._perform_single_delete(event, quoted_file):
                    yield res
                return
            yield event.plain_result("â“ ç”¨æ³•: /åˆ é™¤ <åºå·> æˆ– /åˆ é™¤ <1,2,3> æˆ– /åˆ é™¤ <æ–‡ä»¶å> [åºå·/0/1,2,3] æˆ– å¼•ç”¨æ–‡ä»¶æ¶ˆæ¯åè¾“å…¥ /åˆ é™¤")
            return
            
        target = command_parts[1]
        session = self.session_mgr.get_session(group_id, user_id)
        
        # åœºæ™¯ 1: /åˆ é™¤ <åºå·> æˆ– /åˆ é™¤ <1,2,3>
        if target.isdigit() or ',' in target:
            if not session:
                yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œ /æœç´¢ æœç´¢æ–‡ä»¶ã€‚")
                return
            
            # å¤„ç†å¤šé€‰åˆ é™¤ /df 1,2,3
            if ',' in target:
                try:
                    indices = [int(i.strip()) for i in target.split(',') if i.strip().isdigit()]
                    files_to_delete = []
                    for idx in indices:
                        if 1 <= idx <= session.total_count:
                            files_to_delete.append(session.results[idx-1])
                    if files_to_delete:
                        async for res in self._perform_batch_delete(event, files_to_delete):
                            yield res
                        return
                except ValueError:
                    pass
            
            # å¤„ç†å•é€‰æˆ–å…¨é€‰
            index = int(target) if target.isdigit() else -1
            if index == 0:
                # ç‰¹æ®Šåœºæ™¯: /df 0 åˆ é™¤å½“å‰æœç´¢ç»“æœä¸­çš„æ‰€æœ‰æ–‡ä»¶
                async for res in self._perform_batch_delete(event, session.results):
                    yield res
                return
            if 1 <= index <= session.total_count:
                file_to_delete = session.results[index - 1]
                async for res in self._perform_single_delete(event, file_to_delete, session):
                    yield res
            elif index != -1:
                yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼æœ‰æ•ˆèŒƒå›´: 1-{session.total_count}")
            return
            
        # åœºæ™¯ 2: /df <æ–‡ä»¶å> [åºå·/0/æ‰¹é‡åºå·]
        filename_to_find = target
        index_str = command_parts[2] if len(command_parts) > 2 else None
        
        # ä¼˜å…ˆä½¿ç”¨ä¼šè¯ç¼“å­˜
        found_files = []
        if session and session.keyword == filename_to_find:
            found_files = session.results
        else:
            all_files = await self._get_all_files_recursive_core(group_id, event.bot)
            found_files = [f for f in all_files if filename_to_find in f.get('file_name', '')]

        if not found_files:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶ã€Œ{filename_to_find}ã€ã€‚")
            return

        # æ‰¹é‡åˆ é™¤ (/df <æ–‡ä»¶å> 0) æˆ– (/df <æ–‡ä»¶å> 1,2,3)
        if index_str:
            if index_str == '0':
                async for res in self._perform_batch_delete(event, found_files):
                    yield res
                return
            elif ',' in index_str:
                try:
                    indices = [int(i.strip()) for i in index_str.split(',') if i.strip().isdigit()]
                    files_to_delete = []
                    for idx in indices:
                        if 1 <= idx <= len(found_files):
                            files_to_delete.append(found_files[idx-1])
                    if files_to_delete:
                        async for res in self._perform_batch_delete(event, files_to_delete):
                            yield res
                        return
                except ValueError:
                    pass

        if len(found_files) == 1 and not index_str:
            async for res in self._perform_single_delete(event, found_files[0], session):
                yield res
        elif index_str and index_str.isdigit():
            idx = int(index_str)
            if 1 <= idx <= len(found_files):
                async for res in self._perform_single_delete(event, found_files[idx-1], session):
                    yield res
            else:
                yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼å…±æ‰¾åˆ° {len(found_files)} ä¸ªæ–‡ä»¶ã€‚")
        else:
            # å¤šä¸ªç»“æœï¼Œæ›´æ–°ä¼šè¯å¹¶æ˜¾ç¤º
            session = self.session_mgr.create_session(group_id, user_id, filename_to_find, found_files, self.search_results_per_page)
            async for res in self._show_search_page(event, session, 1):
                yield res

    @filter.command("rn", alias={"é‡å‘½å"})
    async def on_rename_command(self, event: AstrMessageEvent):
        """é‡å‘½åæŒ‡å®šçš„ç¾¤æ–‡ä»¶"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        group_id = int(group_id_str)
        user_id = int(event.get_sender_id())
        command_parts = event.message_str.split()
        
        # æƒé™æ ¡éªŒ
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œæ­¤æ“ä½œçš„æƒé™ã€‚")
            return

        # è§£æå¼•ç”¨çš„æ–‡ä»¶
        quoted_file = await self._resolve_file_from_message(event)

        file_to_rename = None
        session = None
        new_name = None

        if quoted_file:
            if len(command_parts) < 2:
                yield event.plain_result("â“ ç”¨æ³•: å¼•ç”¨æ–‡ä»¶åè¾“å…¥ /é‡å‘½å <æ–°æ–‡ä»¶å>")
                return
            file_to_rename = quoted_file
            new_name = command_parts[1]
            logger.info(f"[/rn] ä½¿ç”¨å¼•ç”¨æ–‡ä»¶: {file_to_rename['file_name']} -> {new_name}")
        else:
            if len(command_parts) < 3:
                yield event.plain_result("â“ ç”¨æ³•: /rn <åºå·> <æ–°æ–‡ä»¶å> æˆ– /rn <æ—§æ–‡ä»¶å> <æ–°æ–‡ä»¶å>")
                return
            
            target = command_parts[1]
            new_name = command_parts[2]
            session = self.session_mgr.get_session(group_id, user_id)
            
            # åœºæ™¯ 1: /é‡å‘½å <åºå·> <æ–°åç§°>
            if target.isdigit():
                if not session:
                    yield event.plain_result("âŒ è¯·å…ˆæ‰§è¡Œ /æœç´¢ æœç´¢æ–‡ä»¶ã€‚")
                    return
                index = int(target)
                if 1 <= index <= session.total_count:
                    file_to_rename = session.results[index - 1]
                else:
                    yield event.plain_result(f"âŒ åºå·é”™è¯¯ï¼æœ‰æ•ˆèŒƒå›´: 1-{session.total_count}")
                    return
            else:
                # åœºæ™¯ 2: /rn <æ—§æ–‡ä»¶å> <æ–°åç§°>
                all_files = await self._get_all_files_recursive_core(group_id, event.bot)
                found_files = [f for f in all_files if target == f.get('file_name', '')]
                
                if not found_files:
                    # æ¨¡ç³ŠåŒ¹é…
                    found_files = [f for f in all_files if target in f.get('file_name', '')]
                
                if not found_files:
                    yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶ã€Œ{target}ã€ã€‚")
                    return
                
                if len(found_files) == 1:
                    file_to_rename = found_files[0]
                else:
                    # å¤šä¸ªç»“æœï¼Œæ›´æ–°ä¼šè¯å¹¶æç¤º
                    session = self.session_mgr.create_session(group_id, user_id, target, found_files, 20)
                    async for res in self._show_search_page(event, session, 1):
                        yield res
                    yield event.plain_result(f"ğŸ’¡ æ‰¾åˆ°å¤šä¸ªåŒ¹é…æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ /é‡å‘½å <åºå·> {new_name} æ¥æŒ‡å®šã€‚")
                    return

        if file_to_rename:
            old_name = file_to_rename.get("file_name")
            file_id = file_to_rename.get("file_id")
            parent_id = file_to_rename.get("parent_id", "/") 
            
            success, message = await rename_group_file(
                self.bot, 
                group_id, 
                file_id, 
                parent_id, 
                new_name
            )
            
            if success:
                yield event.plain_result(f"âœ… æ–‡ä»¶é‡å‘½åæˆåŠŸï¼š\nã€Œ{old_name}ã€\n  â¡ï¸ ã€Œ{new_name}ã€")
                # æ›´æ–°ä¼šè¯ä¸­çš„ç¼“å­˜
                if session and file_to_rename in session.results:
                    file_to_rename["file_name"] = new_name
            else:
                yield event.plain_result(f"âŒ é‡å‘½åå¤±è´¥ï¼š{message}")

    async def _resolve_file_from_message(self, event: AstrMessageEvent) -> Optional[Dict]:
        """
        å‚è€ƒ filechecker é€»è¾‘ï¼šä»æ¶ˆæ¯ï¼ˆå°¤å…¶æ˜¯å¼•ç”¨æ¶ˆæ¯ï¼‰ä¸­è§£æå¹¶è·å–äº‘ç«¯çœŸå®æœ‰æ•ˆçš„ç¾¤æ–‡ä»¶ä¿¡æ¯ã€‚
        """
        group_id = int(event.get_group_id())
        messages = event.get_messages()
        
        file_name_in_msg = None
        msg_file_id = None
        
        for seg in messages:
            if isinstance(seg, Comp.Reply):
                reply_chain = getattr(seg, 'chain', None)
                if reply_chain and isinstance(reply_chain, list):
                    for reply_seg in reply_chain:
                        if isinstance(reply_seg, Comp.File):
                            file_name_in_msg = getattr(reply_seg, "file_name", None) or getattr(reply_seg, "name", None)
                            msg_file_id = getattr(reply_seg, "file_id", None)
                            break
                if file_name_in_msg: break
            elif isinstance(seg, Comp.File):
                # ç›´æ¥æ¶ˆæ¯ä¸­çš„æ–‡ä»¶
                file_name_in_msg = getattr(seg, "file_name", None) or getattr(seg, "name", None)
                msg_file_id = getattr(seg, "file_id", None)
                break
                
        if not file_name_in_msg:
            return None
            
        logger.info(f"å°è¯•è§£ææ¶ˆæ¯ä¸­çš„æ–‡ä»¶ '{file_name_in_msg}' (ID: {msg_file_id})...")
        all_files = await self._get_all_files_recursive_core(group_id, self.bot)
        
        # 1. å°è¯•é€šè¿‡ ID åŒ¹é…
        if msg_file_id:
            target = next((f for f in all_files if f.get('file_id') == msg_file_id), None)
            if target:
                return target
                
        # 2. å°è¯•é€šè¿‡æ–‡ä»¶åå…¨ååŒ¹é…
        target = next((f for f in all_files if f.get('file_name') == file_name_in_msg), None)
        if target:
            return target
            
        return None

    async def _perform_single_delete(self, event: AstrMessageEvent, file_info: dict, session=None):
        group_id = int(event.get_group_id())
        file_name = file_info.get("file_name")
        file_id = file_info.get("file_id")
        
        if not file_id:
            yield event.plain_result(f"âŒ æ— æ³•è·å–æ–‡ä»¶ã€Œ{file_name}ã€çš„IDã€‚")
            return
            
        try:
            delete_result = await event.bot.api.call_action('delete_group_file', group_id=group_id, file_id=file_id)
            is_success = False
            if delete_result:
                trans_result = delete_result.get('transGroupFileResult', {})
                result_obj = trans_result.get('result', {})
                if result_obj.get('retCode') == 0:
                    is_success = True
            
            if is_success:
                yield event.plain_result(f"âœ… æ–‡ä»¶ã€Œ{file_name}ã€å·²æˆåŠŸåˆ é™¤ã€‚")
                if session and file_info in session.results:
                    session.results.remove(file_info)
                    session.total_count = len(session.results)
            else:
                wording = delete_result.get('wording', 'APIæœªè¿”å›æˆåŠŸçŠ¶æ€')
                yield event.plain_result(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{file_name}ã€å¤±è´¥ï¼š{wording}")
        except Exception as e:
            logger.error(f"[{group_id}] åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}", exc_info=True)
            yield event.plain_result(f"âŒ åˆ é™¤æ–‡ä»¶ã€Œ{file_name}ã€æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚")

    async def _perform_batch_delete(self, event: AstrMessageEvent, files_to_delete: List[Dict]):
        async for res in perform_batch_delete(event, files_to_delete):
            yield res

    async def _cleanup_folder(self, path: str):
        await cleanup_folder(path)

    async def _get_file_preview(self, event: AstrMessageEvent, file_info: dict, inner_path: str = None) -> tuple[str, str | None]:
        return await get_file_preview(
            int(event.get_group_id()), 
            file_info, 
            event.bot, 
            self.default_zip_password, 
            self.preview_length, 
            self.download_semaphore,
            self._cleanup_folder,
            inner_path
        )

    async def _create_zip_archive(self, source_dir: str, target_zip_path: str, password: str) -> bool:
        return await create_zip_archive(source_dir, target_zip_path, password)

    async def _perform_group_file_backup(self, event: AstrMessageEvent, group_id: int, date_filter_timestamp: Optional[int] = None):
        async for res in perform_group_file_backup(
            event, 
            group_id, 
            self.bot, 
            self.download_semaphore, 
            self.backup_file_size_limit_mb,
            self.backup_file_extensions,
            self.backup_zip_password,
            date_filter_timestamp
        ):
            yield res

    @filter.command("ddf", alias={"é‡å¤æ–‡ä»¶æ£€æµ‹","é‡å¤ç¾¤æ–‡ä»¶æ£€æµ‹","ç¾¤æ–‡ä»¶æŸ¥é‡"})
    async def on_detect_duplicates_command(self, event: AstrMessageEvent):
        """æ£€æµ‹ç¾¤æ–‡ä»¶ä¸­çš„é‡å¤æ–‡ä»¶ï¼ˆä½¿ç”¨LLMåˆ†æï¼‰"""
        if not self.bot: self.bot = event.bot
        group_id_str = event.get_group_id()
        if not group_id_str:
            yield event.plain_result("âŒ æ­¤æŒ‡ä»¤åªèƒ½åœ¨ç¾¤èŠä¸­ä½¿ç”¨ã€‚")
            return
        
        user_id = int(event.get_sender_id())
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œé‡å¤æ–‡ä»¶æ£€æµ‹çš„æƒé™ã€‚")
            return
        
        async for result in detect_duplicates(
            event, 
            self.bot, 
            self.context, 
            self.admin_users, 
            self.group_whitelist, 
            self._get_all_files_recursive_core, 
            self.text_to_image
        ):
            yield result

    @filter.command("gfb", alias={"å¤‡ä»½ç¾¤æ–‡ä»¶","ç¾¤æ–‡ä»¶å¤‡ä»½"})
    async def on_group_file_backup_command(self, event: AstrMessageEvent):
        """å¤‡ä»½æŒ‡å®šç¾¤èŠæˆ–å½“å‰ç¾¤èŠçš„ç¾¤æ–‡ä»¶"""
        if not self.bot: self.bot = event.bot
        
        # 1. è§£æç›®æ ‡ç¾¤IDå’Œæ—¥æœŸå‚æ•°
        group_id_str = event.get_group_id()
        user_id = int(event.get_sender_id())
        
        command_parts = event.message_str.split()
        target_group_id: Optional[int] = None
        date_filter_timestamp: Optional[int] = None
        
        # è§£æå‚æ•°: /gfb [ç¾¤å·] [æ—¥æœŸ]
        if len(command_parts) > 1:
            try:
                target_group_id = int(command_parts[1])
                # å¦‚æœæœ‰ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œå°è¯•è§£æä¸ºæ—¥æœŸ
                if len(command_parts) > 2:
                    date_filter_timestamp = utils.parse_date_param(command_parts[2])
                    if date_filter_timestamp is None:
                        yield event.plain_result("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ã€‚æ”¯æŒæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD\nç¤ºä¾‹: /gfb 123456 2024-01-01")
                        return
            except ValueError:
                # å¯èƒ½ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ—¥æœŸè€Œä¸æ˜¯ç¾¤å·
                if group_id_str:
                    target_group_id = int(group_id_str)
                    date_filter_timestamp = utils.parse_date_param(command_parts[1])
                    if date_filter_timestamp is None:
                        yield event.plain_result("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·æä¾›æœ‰æ•ˆçš„ç¾¤å·æˆ–æ—¥æœŸã€‚\nç”¨æ³•: /gfb [ç¾¤å·] [æ—¥æœŸ]\næ—¥æœŸæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD")
                        return
                else:
                    yield event.plain_result("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·æä¾›æœ‰æ•ˆçš„ç¾¤å·ã€‚ç”¨æ³•: /gfb <ç¾¤å·> [æ—¥æœŸ]")
                    return
        elif group_id_str:
            # ç¾¤èŠä¸­ä¸”æ²¡æœ‰å‚æ•°ï¼Œå¤‡ä»½å½“å‰ç¾¤
            target_group_id = int(group_id_str)
        else:
            # ç§èŠä¸­ä¸”æ²¡æœ‰å‚æ•°
            yield event.plain_result("âŒ æ ¼å¼é”™è¯¯ï¼šåœ¨ç§èŠä¸­è¯·æŒ‡å®šè¦å¤‡ä»½çš„ç¾¤å·ã€‚\nç”¨æ³•: /gfb <ç¾¤å·> [æ—¥æœŸ]\næ—¥æœŸæ ¼å¼: YYYY-MM-DD, YYYYMMDD, YYYY/MM/DD")
            return

        logger.info(f"ç”¨æˆ· {user_id} è§¦å‘ /gfb å¤‡ä»½æŒ‡ä»¤ï¼Œç›®æ ‡ç¾¤ID: {target_group_id}, æ—¥æœŸç­›é€‰: {command_parts[2] if len(command_parts) > 2 else 'æ— '}")

        # 2. æƒé™å’Œç™½åå•æ ¡éªŒ
        if user_id not in self.admin_users:
            yield event.plain_result("âš ï¸ æ‚¨æ²¡æœ‰æ‰§è¡Œç¾¤æ–‡ä»¶å¤‡ä»½æ“ä½œçš„æƒé™ã€‚")
            return
        
        if self.group_whitelist and target_group_id not in self.group_whitelist:
            yield event.plain_result("âš ï¸ ç›®æ ‡ç¾¤èŠä¸åœ¨æ’ä»¶é…ç½®çš„ç™½åå•ä¸­ï¼Œæ“ä½œå·²æ‹’ç»ã€‚")
            return

        # 3. æ‰§è¡Œå¤‡ä»½ä»»åŠ¡
        async for res in self._perform_group_file_backup(event, target_group_id, date_filter_timestamp):
            yield res

    async def terminate(self):
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] æ­£åœ¨å¸è½½ï¼Œå–æ¶ˆæ‰€æœ‰ä»»åŠ¡...")

        if self.scheduler and self.scheduler.running:
            try:
                self.scheduler.shutdown(wait=False) 
                logger.info("APScheduler å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²æˆåŠŸåœæ­¢ã€‚")
            except Exception as e:
                logger.error(f"åœæ­¢ APScheduler æ—¶å‘ç”Ÿé”™è¯¯: {e}")

        for task in self.active_tasks:
            if not task.done():
                task.cancel()
        
        try:
            await asyncio.gather(*self.active_tasks, return_exceptions=True)
        except asyncio.CancelledError:
            pass
        
        logger.info("æ’ä»¶ [ç¾¤æ–‡ä»¶ç³»ç»ŸGroupFS] å·²å¸è½½ã€‚")
